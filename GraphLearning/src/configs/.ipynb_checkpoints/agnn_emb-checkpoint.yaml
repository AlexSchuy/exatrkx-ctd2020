output_dir: ${SCRATCH}/ExaTrkX/processed_sparse/results/high_003

trainer:
    name: gnn_sparse

data:
    name: hitgraphs_sparse
    input_dir: ${SCRATCH}/ExaTrkX/processed_sparse/adjacent/doublets/high_fullsplit/
    n_train: 56000
    n_valid: 1600
    real_weight: 2.5   # 0.5 / 0.2
    batch_size: 4
    n_workers: 4

model:
    name: resgnn
    input_dim: 3
    hidden_dim: 64
    hidden_activation: Tanh
    n_graph_iters: 8
    layer_norm: true
    loss_func: binary_cross_entropy_with_logits

optimizer:
    name: Adam
    learning_rate: 0.001
    weight_decay: 0.0001
#     lr_scaling: sqrt
#     lr_warmup_epochs: 5
#     lr_decay_schedule:
#         - {start_epoch: 15, end_epoch: 45, factor: 0.5}
#         - {start_epoch: 45, end_epoch: 90, factor: 0.2}
#         - {start_epoch: 45, end_epoch: 60, factor: 0.1}
#         - {start_epoch: 60, end_epoch: 75, factor: 0.05}
#         - {start_epoch: 75, end_epoch: 90, factor: 0.02}

training:
    n_total_epochs: 90